{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract SG and BBox\n",
    "Extract into 2 distinct files to process. The joblib is the result after running SGG of the 1st step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "sgg = {}\n",
    "bbox = {}\n",
    "joblib_file = 'path/to/sgg_joblib/file.joblib'\n",
    "\n",
    "data = joblib.load(joblib_file)\n",
    "list_days = list(data.keys())\n",
    "for day in list_days:\n",
    "    sgg[day] = {}\n",
    "    bbox[day] = {}\n",
    "    list_images = list(data[day].keys())\n",
    "    for img_id in list_images:\n",
    "        sgg[day][img_id] = data[day][img_id]['sgg']\n",
    "        bbox[day][img_id] = data[day][img_id]['bbox']\n",
    "\n",
    "joblib.dump(sgg, 'sgg_lsc2018.joblib')\n",
    "joblib.dump(bbox, 'bbox_lsc2018.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed the SG\n",
    "This works as the following steps:\n",
    "1. Remove predictions with low score\n",
    "2. Merge some overlay bbox in the SGG\n",
    "3. Prune edges as we only allow 1 edge connecting 2 objects\n",
    "4. Get fully connected graph\n",
    "5. Maximum spanning tree\n",
    "6. Embedding to 2 matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "import utils as ut\n",
    "import vrg_lib\n",
    "import graph_lib\n",
    "import sgg_lib\n",
    "\n",
    "VG_SGG_DICTS = '/home/nmduy/Scene-Graph-Benchmark.pytorch/datasets/vg/VG-SGG-dicts-with-attri.json' # ENCODED DICTIONARY FROM VISUAL GENOME DATASET (PROVIDED IN THE ORIGINAL REPO OF KAIHUATANG)\n",
    "IMG_FOLDER = '/mnt/DATA/lsc2020/' # FOLDER CONTAINING ALL LIFELOG IMAGES\n",
    "SGG_JOBLIB = 'data_joblib/sgg_lsc2018.joblib' # OUTPUT FILE OF ABOVE CELL\n",
    "BBOX_JOBLIB = 'data_joblib/bbox_lsc2018.joblib' # OUTPUT FILE OF ABOVE CELL\n",
    "\n",
    "with open(VG_SGG_DICTS) as f:\n",
    "    info_dict = json.load(f)\n",
    "    \n",
    "print('Loading joblib files ...')\n",
    "sgg = joblib.load(SGG_JOBLIB)\n",
    "bbox = joblib.load(BBOX_JOBLIB)\n",
    "print('Loading joblib files --> DONE!')\n",
    "list_days = list(sgg.keys())\n",
    "list_days = sorted(list_days)\n",
    "\n",
    "# score_nodes = {}\n",
    "# score_preds = {}\n",
    "score = {}\n",
    "sgg_dicts = {}\n",
    "graph_dicts = {}\n",
    "\n",
    "## Process all days\n",
    "for idx_day in range(len(list_days)):\n",
    "    sample_day = sgg[list_days[idx_day]]\n",
    "    list_images = list(sample_day.keys())\n",
    "    list_images = sorted(list_images)\n",
    "    print(f\"Processing folder {list_days[idx_day]}: {len(list_images)} images\")\n",
    "    \n",
    "    ## Process all images in 1 day\n",
    "    for idx_image in tqdm(range(len(list_images))):\n",
    "        img_id = list_images[idx_image]\n",
    "        sample_sgg = sample_day[img_id]\n",
    "        sample_bbox = bbox[list_days[idx_day]][img_id]\n",
    "        discard = False\n",
    "        if len(sample_sgg) == 0:\n",
    "            if len(sample_bbox) > 0 and len(sample_bbox['labels']) > 0:\n",
    "                G_refill = graph_lib.create_Graph_from_objects(sample_bbox['labels'], sample_bbox['bbox'], info_dict)\n",
    "            else:\n",
    "                discard = True\n",
    "                print(f\"Discard images: {img_id}\")\n",
    "        else:        \n",
    "            ## Filter lower score objects\n",
    "            try:\n",
    "                filter_sgg, filter_bbox = sgg_lib.filter_triplet(sample_sgg, sample_bbox, thres_obj=0.2, thres_rel=1e-4)\n",
    "            except:\n",
    "                print(f\"[Filter error] idx_day: {idx_day}, idx_image: {idx_image}\")\n",
    "                print(f\"Error:\\n {sys.exc_info()}\")\n",
    "                exit() \n",
    "\n",
    "            ## Merge overlay objects\n",
    "            try:\n",
    "                overlay_sgg, overlay_bbox = sgg_lib.remove_overlay_objects(filter_sgg, filter_bbox)\n",
    "            except:\n",
    "                print(f\"[Overlay error] idx_day: {idx_day}, idx_image: {idx_image}, img_id: {img_id}\")\n",
    "                print(f\"Error:\\n {sys.exc_info()}\")\n",
    "                exit() \n",
    "\n",
    "            ## Prune to have only 1 edge between 2 objects\n",
    "            #prune_bbox = overlay_bbox.copy()\n",
    "            try:\n",
    "                prune_sgg = sgg_lib.prune_single_predicate_each_pair(overlay_sgg)\n",
    "                G_prune = graph_lib.create_Graph(prune_sgg, overlay_bbox['bbox'], info_dict) # Create graph\n",
    "            except:\n",
    "                print(f\"[Prune error] idx_day: {idx_day}, idx_image: {idx_image}, img_id: {img_id}\")\n",
    "                print(f\"Error:\\n {sys.exc_info()}\")\n",
    "                exit()\n",
    "\n",
    "            ## Expand the spatial\n",
    "            #expand_bbox = prune_bbox.copy()\n",
    "            try:\n",
    "                expand_sgg = sgg_lib.get_fully_connected_graph(prune_sgg, overlay_bbox)\n",
    "            except:\n",
    "                print(f\"[VDG error] idx_day: {idx_day}, idx_image: {idx_image}, img_id: {img_id}\")\n",
    "                print(f\"Error:\\n {sys.exc_info()}\")\n",
    "                exit()\n",
    "\n",
    "            ## Create Graph\n",
    "            G_fc = graph_lib.create_Graph(expand_sgg, overlay_bbox['bbox'], info_dict)\n",
    "\n",
    "            ## MST\n",
    "            G_mst = nx.algorithms.tree.mst.maximum_spanning_tree(G=G_fc.to_undirected(), weight='score')\n",
    "\n",
    "            ## Merge graphs: MST Graph + Prune Graph + priority for Prune Graph (keep_origin=False)\n",
    "            G_merge, merge_sgg = graph_lib.merge_Graphs(G_mst, G_prune, keep_origin=False)\n",
    "\n",
    "            ## Add object detected but no predicated (alone node)\n",
    "            try:\n",
    "                G_refill = graph_lib.fill_in_single_node_from_bbox(G_merge, overlay_bbox, info_dict)\n",
    "            except:\n",
    "                print(f\"[Fill-in error] idx_day: {idx_day}, idx_image: {idx_image}, img_id: {img_id}\")\n",
    "                print(f\"Error:\\n {sys.exc_info()}\")\n",
    "                exit()\n",
    "        \n",
    "        if discard:\n",
    "            node_matrix = []\n",
    "            pred_matric = []\n",
    "            merge_sgg = []\n",
    "            overlay_bbox = []\n",
    "            G_refill = None\n",
    "        else:\n",
    "            ## Embed to get score matrix\n",
    "            node_matrix, pred_matrix = graph_lib.get_graph_embedding_concatenate(G_refill)\n",
    "        \n",
    "        ## Assign to dict\n",
    "        # score_nodes[img_id] = node_matrix\n",
    "        # score_preds[img_id] = pred_matrix\n",
    "        score[img_id] = {}\n",
    "        score[img_id]['nodes'] = node_matrix\n",
    "        score[img_id]['edges'] = pred_matrix\n",
    "        sgg_dicts[img_id] = {}\n",
    "        sgg_dicts[img_id]['sgg'] = merge_sgg\n",
    "        sgg_dicts[img_id]['bbox'] = overlay_bbox\n",
    "        graph_dicts[img_id] = G_refill\n",
    "        \n",
    "print('Saving ...')\n",
    "# joblib.dump(score_nodes, 'node_embed_lsc2018.joblib')\n",
    "# joblib.dump(score_preds, 'pred_embed_concatenate_lsc2018.joblib')\n",
    "joblib.dump(score, 'score_matrix_concatenate_lsc2018.joblib')\n",
    "joblib.dump(sgg_dicts, 'sgg_mst_lsc2018.joblib')\n",
    "joblib.dump(graph_dicts, 'image_graph_lsc2018.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sgg",
   "language": "python",
   "name": "sgg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
